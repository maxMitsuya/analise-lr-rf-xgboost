# ğŸ“Š AnÃ¡lise Comparativa de Modelos de PrevisÃ£o de Churn

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0.2-orange)
![XGBoost](https://img.shields.io/badge/XGBoost-1.5.0-green)
![Imbalanced-Learn](https://img.shields.io/badge/Imbalanced--Learn-0.9.0-yellow)

Projeto comparando RegressÃ£o LogÃ­stica, Random Forest e XGBoost para previsÃ£o de churn em e-commerce, com otimizaÃ§Ã£o de hiperparÃ¢metros via GridSearchCV.

## ğŸ¯ Objetivo
Desenvolver e comparar modelos preditivos para identificar clientes com risco de cancelamento, permitindo aÃ§Ãµes preventivas para reduÃ§Ã£o de churn.

## ğŸ“Š Dataset
Dados de comportamento de clientes de e-commerce contendo:

| VariÃ¡vel | DescriÃ§Ã£o | Problemas Identificados |
|----------|-----------|-------------------------|
| HourSpendOnApp | Tempo no app | Valores nulos tratados |
| SatisfactionScore | NÃ­vel de satisfaÃ§Ã£o | - |
| DaySinceLastOrder | Dias desde Ãºltima compra | Forte correlaÃ§Ã£o com churn |
| CashbackAmount | Valor de cashback | RelaÃ§Ã£o negativa com churn |

## ğŸ“ˆ AnÃ¡lise ExploratÃ³ria

### Matriz de CorrelaÃ§Ã£o
![Correlation Heatmap](https://github.com/maxMitsuya/analise-lr-rf-xgboost/blob/main/corr.png)
*CorrelaÃ§Ã£o entre features e variÃ¡vel target (Churn)*

### Principais Insights:
- **DaySinceLastOrder**: -0.16 (forte relaÃ§Ã£o negativa)
- **CashbackAmount**: -0.15 (impacto negativo no churn)
- **SatisfactionScore**: 0.11 (relaÃ§Ã£o positiva)

## ğŸ¤– Modelagem

### ğŸ”§ Pipeline de Processamento
```python
pipeline = Pipeline([
    ('smote', SMOTE(random_state=42)),
    ('model', None)
])
```

## ğŸ“Š ComparaÃ§Ã£o de Modelos

| Modelo                     | F1-Score | Recall | ROC AUC |
|----------------------------|----------|--------|---------|
| XGBoost (Otimizado)        | 0.679    | 0.742  | 0.912   |
| Random Forest (Otimizado)   | 0.605    | 0.516  | 0.872   |
| RegressÃ£o LogÃ­stica        | 0.383    | 0.637  | 0.650   |

## ğŸ“‰ GrÃ¡fico de ComparaÃ§Ã£o
![Model Comparison](https://github.com/maxMitsuya/analise-lr-rf-xgboost/blob/main/results.png)  
*Desempenho dos modelos em diferentes mÃ©tricas*

## ğŸ† Melhor Modelo: XGBoost Otimizado

### âš™ï¸ ParÃ¢metros Otimizados
```python
{
    'learning_rate': 0.1,
    'max_depth': 6,
    'n_estimators': 200,
    'scale_pos_weight': 3.45
}
```
## ğŸ“Š Matriz de ConfusÃ£o
![Confusion Matrix](https://github.com/maxMitsuya/analise-lr-rf-xgboost/blob/main/confusion_matrix.png)  
*Performance do modelo em prever churn (74.2% de recall)*

## ğŸ’¡ Insights Finais

### Principais Descobertas
- **XGBoost** apresentou o melhor desempenho geral:  
  - Recall de 74.2% (melhor detecÃ§Ã£o de churn real)  
  - F1-Score de 67.9% (melhor equilÃ­brio entre precisÃ£o e recall)

- **Fatores-chave identificados**:  
  - ğŸ”´ **Dias sem comprar**: VariÃ¡vel mais preditiva de churn (correlaÃ§Ã£o negativa de -0.16)  
  - ğŸŸ¢ **Cashback**: Efeito protetor contra cancelamentos (correlaÃ§Ã£o negativa de -0.15)  
  - â±ï¸ **Tempo no app**: Impacto neutro (correlaÃ§Ã£o de apenas 0.02)

- **Resultados operacionais**:  
  - Modelo capaz de identificar 74% dos casos reais de churn  
  - Para cada 100 alertas de churn, 63 sÃ£o corretos (precisÃ£o de 63%)  
  - AUC-ROC de 91.2% indica excelente capacidade discriminatÃ³ria
